---
title: "回归分析"
author: "邹涛"
date: "`r Sys.Date()`"
output:
  rmdformats::readthedown:
    self_contained: true
    thumbnails: true
    lightbox: true
    gallery: false
    highlight: tango
---

```{r setup, include=FALSE}
## Global options
knitr::opts_chunk$set(cache = TRUE)
```

```{r include=FALSE}
setwd("F:/学习文件集/考研/Statistics/Regression Analysis")
```

# 一元线性回归
设$\begin{matrix}y_1&y_2&\cdots&y_{n-1}&y_n\\x_1&x_2&\cdots&x_{n-1}&x_n\end{matrix}$为来自总体$(X,Y)$的$n$组样本。

## 假设
$$y_i=\beta_0+\beta_1x_i+\varepsilon_i\ \ \ (i=1,2,\cdots,n)$$，其中$\varepsilon_i\sim N(0,\sigma^2)$（$\sigma^2$未知），且诸$\varepsilon_i$“绝对”独立。

## 系数估计
**<font color="red" size=4>最小二乘法</font>**：

目标：系数值使得$Q(\beta_0,\beta_1)=\sum_{i=1}^n(y_i-\beta_0-\beta_1x_i)^2$最小。

解得：$\hat{\beta}_1=\frac{\sum(x_i-\bar{x})(y_i-\bar{y})}{\sum(x_i-\bar{x})^2}=\frac{l_{xy}}{l_{xx}}\ \ \ \hat{\beta}_0=\bar{y}-\hat{\beta}_1$

根据假设，进一步可得：$\hat{\beta}_1\sim N(\beta_1,\frac{\sigma^2}{l_{xx}})\ \ \ \hat{\beta}_0\sim N(\beta_0,(\frac{1}{n}+\frac{\bar{x}^2}{l_{xx}})\sigma^2)\ \ \ Cov(\hat{\beta}_1,\hat{\beta}_0)=-\frac{\bar{x}}{l_{xx}}\sigma^2$

**<font color="red" size=4>最大似然估计</font>**：与最小二乘估计等同。

## 检验
检验目标：$H_0:\beta_1\neq0\ \ vs\ \ H_1:\beta_1=0$

以下是三个等价检验方法。

**<font color="red" size=4>F检验</font>**：

总偏差平方和$SST=\sum(y_i-\bar{y})^2$；回归平方和$SSR=\sum(\hat{y}_i-\bar{y})^2$；残差平方和$SSE=\sum(\hat{y}_i-y_i)^2$；（$SST=SSR+SSE$）

根据“假设”，有：

(1) $\frac{SSE}{\sigma^2}\sim\chi^2(n-2)$；

(2) 若原假设$H_0:\beta_1\neq0$成立，则有$\frac{SSR}{\sigma^2}\sim\chi^2(1)$；

(3) $SSE$与$SSR$相互独立。

构造$F$统计量$F=\frac{SSR/1}{SSE/(n-2)}\sim F(1,n-2)$进行检验。

**<font color="red" size=4>t检验</font>**：

由$\hat{\beta}_1\sim N(\beta_1,\frac{\sigma^2}{l_{xx}})$与$\frac{SSE}{\sigma^2}\sim\chi^2(n-2)$可得：$$\frac{\hat{\beta}_1-\beta_1}{\sqrt{\frac{SSE}{(n-2)l_{xx}}}}\sim t(n-2)$$，其中$\sqrt{\frac{SSE}{(n-2)l_{xx}}}$是$\hat{\beta}_1$的标准误（标准差的估计）。

**<font color="red" size=4>相关系数检验</font>**：

# 多元线性回归
设$\begin{matrix}y_1&x_{11}&x_{12}&\cdots&x_{1p}\\y_2&x_{21}&x_{22}&\cdots&x_{2p}\\\vdots&\vdots&\vdots&\ddots&\vdots\\y_n&x_{n1}&x_{x2}&\cdots&x_{np}\end{matrix}$为来自总体$(Y,X_1,\cdots,X_p)$的$n$组样本。

## 假设
$$y_i=\beta_0+\beta_1x_{i1}+\beta_2x_{i2}+\cdots+\beta_px_{ip}+\varepsilon_i$$，其中：

(1) $\varepsilon_i\sim N(0,\sigma^2)$（$\sigma^2$未知），且诸$\varepsilon_i$“绝对”独立；

(2) $Cov(X_i,X_j)=0\ \ \ (1\leq i<j\leq p)$；

(3) $Rank(X)=p+1<n$，$X$为$n\times(p+1)$维资料矩阵。

## 系数估计
**<font color="red" size=4>最小二乘法</font>**：

解得：$\boldsymbol{\hat{\beta}}=(X^TX)^{-1}X^T\boldsymbol{y}$

根据假设，进一步得：

$$\boldsymbol{\hat{\beta}}\sim N(\boldsymbol{\beta},\sigma^2(X^TX)^{-1})$$

**<font color="red" size=4>最大似然估计</font>**：与最小二乘估计等同。

## 检验
**<font color="red" size=4>F检验</font>**：

检验目标：$H_0:\beta_0=\beta_1=\cdots=\beta_p=0\ \ vs\ \ 至少有一个\neq0$

根据假设，有：

(1) $\frac{SSE}{\sigma^2}\sim\chi^2(n-p-1)$；

(2) 若$H_0$成立，则$\frac{SSR}{\sigma^2}\sim\chi^2(p)$；

(3) $SSE$与$SSR$相互独立。

构造$F$统计量$F=\frac{SSR/p}{SSE/(n-p-1)}$进行检验。

**<font color="red" size=4>t检验</font>**：

检验目标：$H_0:\beta_j=0\ \ vs\ \ \beta_j\neq0\ \ \ (j=1,2,\cdots,p)$

由$\hat{\beta}_j\sim N(\beta_j,c_{jj}\sigma^2)$与$\frac{SSE}{\sigma^2}\sim\chi^2(n-p-1)$可得：$$\frac{\hat{\beta}_j-\beta_j}{\sqrt{\frac{SSE}{n-p-1}c_{jj}}}\sim t(n-p-1)$$

## 多重共线性
### 诊断方法
(1) 自变量之间显著相关；

(2) $F$检验显著，但几乎所有系数的$t$检验不显著；

(3) 系数的正负号与预期情况正好相反；

(4) 方差膨胀因子。当某一自变量的$VIF\geq10$时说明该自变量与其他自变量存在严重的多重共线性；或当平均$VIF$远大于1时说明存在严重的多重共线性。

$$VIF_i=\frac{1}{1-R_i^2}$$，其中$R_i^2$为$x_i$作为因变量，其他$p-1$个自变量作为自变量进行回归得到的可决系数。

### 处理方法
删除不重要的变量或增加样本量。

## 异方差
### 诊断方法
**<font color="red" size=4>残差图分析</font>**：绘制残差与某一变量的散点图

**<font color="red" size=4>Spearman相关系数检验</font>**：

计算Spearman相关系数$r_s$，再样本量$n>8$的情况下构造统计量：$$t=\frac{\sqrt{n-2}r_s}{\sqrt{1-r_s^2}}\sim t(n-2)$$

### 处理方法
加权最小二乘估计（WLS）：使$Q_w=\sum w_i(y_1-\beta_0-\beta_1x_{i1}-\cdots-\beta_px_{ip})^2$最小，得：$$\boldsymbol{\hat{\beta}}_w=(X^TWX)^{-1}X^TW\boldsymbol{y}$$，其中$W=diag(w_1,\cdots,w_n)$。

通常情况下取：$$w_i=\frac{1}{x_{ij}^m}$$，其中$j\ (j=1,\cdots,p)$为与普通残差的Spearman相关系数最大的变量，$m$通常取seq(from=-2, to=2, by=0.5)。

```{r message=TRUE, warning=FALSE, paged.print=FALSE}
# w <- 1/(x_j**m)
# lm(y ~ x1 + x2, data=data, weights=w)
```

## 自相关

# 变量选择
## 准则1：调整的可决系数
$$R_a^2=1-\frac{n-1}{n-p-1}(1-R^2)$$，其中$R^2=\frac{SSR}{SST}$。$R_a^2$越大，模型越优。

## 准则2：AIC信息量
$$\begin{aligned}AIC&=-2\ln L(\boldsymbol{\hat{\beta}},\boldsymbol{y})+2p\\&=n\ln(2\pi)+n\ln(\frac{SSE}{n})+n+2p\\&\propto n\ln(SSE)+2p\end{aligned}$$，其中$p$为未知参数的数量。AIC越小，模型越优。

## 准则3：$C_p$统计量
$$C_p=(n-m-1)\frac{SSE_p}{SSE_m}+2p$$，其中$SSE_p$对应选模型的残差平方和，$SSE_m$对应全模型的残差平方和。**<font color="orange" size=3>（我很好奇$C_p$统计量咋个计算）</font>**


# Logistic回归
Logistic变换：$f(x)=\frac{1}{1+e^{-x}}$，将$\hat{y}$的值限定在$(0,1)$区间内，对$\hat{y}$较大的情况不敏感。

## 分组数据的Logistic回归模型
当所有解释变量相同时，$0-1$型被解释变量$y$有多个取值。则可以用$\pi$表示$y=1$的比例，将$\ln(\frac{\pi}{1-\pi})$作为被解释变量再与解释变量建立回归模型。

由于每个分组的样本量不同、$y$的两点分布的参数也不同，应该采用加权最小二乘估计，以$n_i\pi_i(1-\pi_i)$为权重。

## 未分组数据的Logistic回归模型
设$\begin{matrix}y_1&x_{11}&x_{12}&\cdots&x_{1p}\\y_2&x_{21}&x_{22}&\cdots&x_{2p}\\\vdots&\vdots&\vdots&\ddots&\vdots\\y_n&x_{n1}&x_{x2}&\cdots&x_{np}\end{matrix}$为来自总体$(Y,X_1,\cdots,X_p)$的$n$组样本，其中$y_i\sim b(1,\pi_i)$，诸$\pi_i$取值未知。

使用最大似然估计法估计诸$\pi_i$，得对数似然函数：$\ln L=\sum\Big{[}\ln(1-\pi_i)+y_i\ln\frac{\pi_i}{1-\pi_i}\Big{]}$

建立模型：$$\pi_i=f(\beta_0+\beta_1x_{i1}+\cdots+\beta_px_{ip})$$，当$f$为Logistic函数时，有：$$\pi_i=\frac{e^{\beta_0+\beta_1x_{i1}+\cdots+\beta_px_{ip}}}{1+e^{\beta_0+\beta_1x_{i1}+\cdots+\beta_px_{ip}}}$$将$\pi_i$代入对数似然函数，利用“数值计算算法”得出$\boldsymbol{\hat{\beta}}$。**<font color="orange" size=3>“数值计算算法”是某种迭代算法，有时无法成功迭代出系数得估计值</font>**

```{r}
# glm(y ~ x, family=binomial(link='logit'), data=data)
```








